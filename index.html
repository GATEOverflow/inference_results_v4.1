
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
        <link rel="next" href="compare/">
      
      
      <link rel="icon" href="img/logo_v2.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.7">
    
    
      
        <title>MLPerf Inference Results Comparison</title>
      
    
    
  
      <link rel="stylesheet" href="assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.06af60db.min.css">
      
      


    
<link rel="stylesheet" rel="preload" as="style" media="all" href="thirdparty/tablesorter/dist/css/jquery.tablesorter.pager.min.css">
<link rel="stylesheet" rel="preload" as="style" media="all" href="thirdparty/tablesorter/dist/css/theme.blackice.min.css">
<link rel="stylesheet" rel="preload" as="style" media="all" href="thirdparty/tablesorter/dist/css/theme.blue.min.css">
<style type="text/css">

table.resultstable, table.counttable {
    overflow-x: auto;
}

.pager1{
    display: none!important;
}

.pagerSavedHeightSpacer {
    display: none!important;
}
.resultstable_wrapper, .counttable_wrapper {
    overflow-x: auto;
}

/* General form styling */
form {
    max-width: 800px;
    margin: 0 auto;
    padding: 20px;
    background-color: #f5f5f5;
    border-radius: 8px;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

/* Style for form group */
.form-group {
    margin-bottom: 20px;
    position: relative;
}

/* Label styling */
label {
    display: block;
    font-size: 14px;
    color: #333;
    margin-bottom: 5px;
    font-weight: 500;
}

/* Select styling */
select {
    width: 100%;
    padding: 10px;
    font-size: 16px;
    color: #333;
    background-color: #fff;
    border: 1px solid #ccc;
    border-radius: 4px;
    box-shadow: none;
    appearance: none;
    transition: border-color 0.3s ease;
}

select:focus {
    border-color: #6200ee;
    outline: none;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

/* Custom arrow for select */
select::-ms-expand {
    display: none;
}

.select-wrapper {
    position: relative;
}

.select-wrapper::after {
    content: '';
    position: absolute;
    top: 50%;
    right: 10px;
    width: 0;
    height: 0;
    border-left: 5px solid transparent;
    border-right: 5px solid transparent;
    border-top: 5px solid #333;
    pointer-events: none;
    transform: translateY(-50%);
}

/* Button styling */
button {
    width: 100%;
    padding: 12px;
    font-size: 16px;
    color: #fff;
    background-color: #6200ee;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    transition: background-color 0.3s ease;
}

button:hover {
    background-color: #3700b3;
}

button:active {
    background-color: #6200ee;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
}

button:disabled {
    background-color: #ccc;
    cursor: not-allowed;
}

/* Input and button ripple effect */
.button-ripple, .input-ripple {
    position: relative;
    overflow: hidden;
}

.button-ripple::after, .input-ripple::after {
    content: '';
    position: absolute;
    top: 50%;
    left: 50%;
    width: 100px;
    height: 100px;
    background: rgba(255, 255, 255, 0.4);
    border-radius: 50%;
    transform: translate(-50%, -50%) scale(0);
    transition: transform 0.5s ease, opacity 1s ease;
    opacity: 0;
    pointer-events: none;
}

.button-ripple:active::after, .input-ripple:focus::after {
    transform: translate(-50%, -50%) scale(1);
    opacity: 1;
    transition: 0s;
}

/* Responsive Design */
@media (max-width: 768px) {
    form {
        max-width: 100%;
        padding: 15px;
    }

    button {
        padding: 10px;
        font-size: 14px;
    }

    select {
        font-size: 14px;
        padding: 8px;
    }
}

@media (max-width: 480px) {
    form {
        padding: 10px;
    }

    button {
        padding: 8px;
        font-size: 14px;
    }

    select {
        font-size: 14px;
        padding: 8px;
    }

    label {
        font-size: 13px;
    }
}

select.pagesize, select.gotoPage {
    width: fit-content;
    padding: 5px;
}


/*Testing*/
/* Base Table Styles */
#results_table {
    margin: 20px 0;
    overflow-x: auto;
}

.tablesorter {
    width: 100%;
    border-collapse: collapse;
    background-color: #fff;
    font-size: 14px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    border-radius: 8px;
    overflow: hidden;
}

/* Header and Footer Styles */
.tablesorter thead th,
.tablesorter tfoot th {
    background-color: #6200ea; /* Material Design Purple */
    color: #ffffff;
    padding: 12px;
    text-align: left;
    text-transform: uppercase;
    font-weight: 500;
    border-bottom: 2px solid #512da8; /* Darker purple for bottom border */
}

.tablesorter tfoot th {
    background-color: #6200ea;
}

/* Body Row Styles */
.tablesorter tbody tr {
    border-bottom: 1px solid #e0e0e0;
    transition: background-color 0.3s ease;
}

.tablesorter tbody tr:nth-child(even) {
    background-color: #f9f9f9;
}

.tablesorter tbody tr:hover {
    background-color: #eeeeee;
}

.tablesorter tbody td {
    padding: 12px;
    text-align: left;
    color: #424242;
}

/* Specific Column Styles */
#col-id,
#col-system,
#col-submitter,
#col-accelerator {
    font-weight: bold;
}
#col-id, .col-id {
    min-width: 80px;
    max-width: 80px;
    width: 80px;
    left: 0px;
}
td.col-result {
    min-width: 100px;
    text-align: right!important;
}
td.col-system, th.col-system {
    min-width: 150px;
    max-width: 150px;
    width: 150px;
    word-break: break-word;
    left: 80px;
}
td.col-submitter, th.col-submitter {
    min-width: 120px;
    max-width: 120px;
    width: 120px;
    word-break: break-word;
    left: 230px;
}
td.col-accelerator, th.col-accelerator {
    min-width: 120px;
    max-width: 120px;
    width: 120px;
    word-break: break-word;
    left: 350px;
}

td.count-submitter, th.count-submitter {
    min-width: 150px;
    max-width: 150px;
    width: 150px;
    left: 0px;
    background: white;
    font-weight: 600;
    font-size: Large;
    word-break: break-word;
    position:sticky;
}
.col-scenario {
    font-weight: 500;
    color: #6200ea;
    text-align: center;
}

.col-result {
    text-align: right;
    color: #303f9f; /* Material Design Blue */
    font-weight: 600;
}

.headcol {
  position: sticky;
  background:white;
  border:none!important;
}

.collapsible {
    color: white;
    cursor: pointer;
    padding: 10px;
    width: 100%;
    border: none;
    text-align: left;
    outline: none;
    font-size: 15px;
}

.chart {
    /* padding: 0 18px; */
    display: none; /* Hidden by default */
    overflow: hidden;
    height: 500px;
    width: 100%;
    background-color: white;
}


/* Responsive Design */
@media (max-width: 768px) {
    .tablesorter thead,
    .tablesorter tfoot {
        display: none;
    }

    .tablesorter tbody tr {
        display: block;
        margin-bottom: 15px;
        border: 1px solid #ddd;
        border-radius: 8px;
    }

    .tablesorter tbody td {
        display: flex;
        justify-content: space-between;
        padding: 10px;
        text-align: right;
    }

    .tablesorter tbody td::before {
        content: attr(data-label);
        font-weight: bold;
        color: #6200ea;
        text-transform: uppercase;
    }

    .tablesorter tbody td:first-child {
        border-top-left-radius: 8px;
        border-bottom-left-radius: 8px;
    }

    .tablesorter tbody td:last-child {
        border-top-right-radius: 8px;
        border-bottom-right-radius: 8px;
    }
}



</style>

  <!-- Add scripts that need to run afterwards here -->

    
  
      
    
<!-- load jQuery and tablesorter scripts -->
<script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>


<script type="text/javascript" src="thirdparty/tablesorter/dist/js/jquery.tablesorter.js"></script>
<!-- tablesorter widgets (optional) -->

<script type="text/javascript" src="thirdparty/tablesorter/dist/js/jquery.tablesorter.widgets.js"></script>
<script type="text/javascript" src="thirdparty/tablesorter/dist/js/extras/jquery.tablesorter.pager.min.js"></script>
  <!-- Add scripts that need to run before here -->
  <script src="https://cdn.canvasjs.com/ga/jquery.canvasjs.min.js"></script>
  
<script type="text/javascript" src="javascripts/config.js"></script>
<script type="text/javascript" src="javascripts/common.js"></script>
  <!-- Add scripts that need to run afterwards here -->

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="blue-grey">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="." title="MLPerf Inference Results Comparison" class="md-header__button md-logo" aria-label="MLPerf Inference Results Comparison" data-md-component="logo">
      
  <img src="img/logo_v2.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MLPerf Inference Results Comparison
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Results
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/mlcommons/inference_results_v4.1" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="." class="md-tabs__link">
        
  
    
  
  Results

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="compare/" class="md-tabs__link">
        
  
    
  
  Compare

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="." title="MLPerf Inference Results Comparison" class="md-nav__button md-logo" aria-label="MLPerf Inference Results Comparison" data-md-component="logo">
      
  <img src="img/logo_v2.svg" alt="logo">

    </a>
    MLPerf Inference Results Comparison
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mlcommons/inference_results_v4.1" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="." class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Results
    
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="compare/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Compare
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  
  



  
  


  <h1>Results</h1>

<html>

        <h2 id="results_heading_available" class="results_table_heading">Datacenter Category: Available submissions in Closed division</h2>

<!-- pager -->
<div class="pager1 PAGER_CLASS">
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/first.png" class="first"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/prev.png" class="prev"/>
            <span class="pagedisplay"></span> <!-- this can be any element, including an input -->
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/next.png" class="next"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/last.png" class="last"/>
            <select class="pagesize" title="Select page size">
            <option selected="selected" value="10">10</option>
            <option value="20">20</option>
            <option value="30">30</option>
            <option value="all">All</option>
            </select>
            <select class="gotoPage" title="Select page number"></select>
</div>

<div id="results_table_available" class="resultstable_wrapper"> <table class="resultstable tablesorter tableclosed tabledatacenter" id="results_available"><thead> <tr>
            <th id="col-id" class="headcol col-id">ID</th>
            <th id="col-system" class="headcol col-system">System</th>
            <th id="col-submitter" class="headcol col-submitter">Submitter</th>
            <th id="col-accelerator" class="headcol col-accelerator">Accelerator</th>
            <th id="col-llama2-99" colspan="2">LLAMA2-70B-99</th>
            <th id="col-llama2-99.9" colspan="2">LLAMA2-70B-99.9</th>
            <th id="col-gptj-99" colspan="2">GPTJ-99</th>
            <th id="col-gptj-99.9" colspan="2">GPTJ-99.9</th>
            <th id="col-bert-99" colspan="2">Bert-99</th>
            <th id="col-bert-99.9" colspan="2">Bert-99.9</th>
            <th id="col-sdxl" colspan="2">Stable Diffusion</th>
            <th id="col-dlrm-v2-99" colspan="2">DLRM-v2-99</th>
            <th id="col-dlrm-v2-99.9" colspan="2">DLRM-v2-99.9</th>
            <th id="col-retinanet" colspan="2">Retinanet</th>
            <th id="col-resnet50" colspan="2">ResNet50</th>
            <th id="col-3d-unet-99" colspan="1">3d-unet-99</th>
            <th id="col-3d-unet-99.9" colspan="1">3d-unet-99.9</th>
            </tr>
        <tr>
        <th class="headcol col-id"></th>
        <th class="headcol col-system"></th>
        <th class="headcol col-submitter"></th>
        <th class="headcol col-accelerator"></th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>
                </tr></thead><tfoot> <tr>
            <th id="col-id" class="headcol col-id">ID</th>
            <th id="col-system" class="headcol col-system">System</th>
            <th id="col-submitter" class="headcol col-submitter">Submitter</th>
            <th id="col-accelerator" class="headcol col-accelerator">Accelerator</th>
            <th id="col-llama2-99" colspan="2">LLAMA2-70B-99</th>
            <th id="col-llama2-99.9" colspan="2">LLAMA2-70B-99.9</th>
            <th id="col-gptj-99" colspan="2">GPTJ-99</th>
            <th id="col-gptj-99.9" colspan="2">GPTJ-99.9</th>
            <th id="col-bert-99" colspan="2">Bert-99</th>
            <th id="col-bert-99.9" colspan="2">Bert-99.9</th>
            <th id="col-sdxl" colspan="2">Stable Diffusion</th>
            <th id="col-dlrm-v2-99" colspan="2">DLRM-v2-99</th>
            <th id="col-dlrm-v2-99.9" colspan="2">DLRM-v2-99.9</th>
            <th id="col-retinanet" colspan="2">Retinanet</th>
            <th id="col-resnet50" colspan="2">ResNet50</th>
            <th id="col-3d-unet-99" colspan="1">3d-unet-99</th>
            <th id="col-3d-unet-99.9" colspan="1">3d-unet-99.9</th>
            </tr>
        <tr>
        <th class="headcol col-id"></th>
        <th class="headcol col-system"></th>
        <th class="headcol col-submitter"></th>
        <th class="headcol col-accelerator"></th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>
                </tr></tfoot>
        <tr>
        <td class="col-id headcol"> v4.1-0001 </td>
        <td class="col-system headcol" title="
Processor: 2xAMD EPYC 9374F
Software: vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/AMD/systems/1xMI300X_2xEPYC-9374F.json"> Supermicro AS-8125GS-TNMR2 </a> </td>
        <td class="col-submitter headcol"> AMD </td>
        <td class="col-accelerator headcol"> AMD Instinct MI300X-NPS1-SPX-192GB-750W x 1 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Server"> 2520.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Offline"> 3062.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Server"> 2520.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline"> 3062.7 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0002 </td>
        <td class="col-system headcol" title="
Processor: 2xAMD EPYC 9374F
Software: vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-9374F.json"> Supermicro AS-8125GS-TNMR2 </a> </td>
        <td class="col-submitter headcol"> AMD </td>
        <td class="col-accelerator headcol"> AMD Instinct MI300X-NPS1-SPX-192GB-750W x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Server"> 21028.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Offline"> 23514.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Server"> 21028.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline"> 23514.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0003 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9654 96-Core Processor
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 96.0
Processors per node: 1
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json"> ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB) </a> </td>
        <td class="col-submitter headcol"> ASUSTeK </td>
        <td class="col-accelerator headcol"> NVIDIA H100-NVL-94GB x 4 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Server"> 5788.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Offline"> 6673.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Server"> 5788.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Offline"> 6673.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Server"> 6070.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Offline"> 6985.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Server"> 6070.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Offline"> 6985.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Server"> 17001.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Offline"> 24173.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Server"> 16002.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Offline"> 20380.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Server"> 5.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Offline"> 5.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99/Server"> 129386.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99/Offline"> 197140.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99.9/Server"> 100009.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99.9/Offline"> 113651.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Server"> 2647.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Offline"> 5288.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/resnet50/Server"> 233275.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/resnet50/Offline"> 270891.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/3d-unet-99/Offline"> 21.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/3d-unet-99.9/Offline"> 21.5 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0004 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9374F 32-Core Processor
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json"> ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> ASUSTeK </td>
        <td class="col-accelerator headcol"> NVIDIA H100-PCIe-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Server"> 8094.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Offline"> 9281.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Server"> 8094.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Offline"> 9281.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Server"> 7986.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Offline"> 13078.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Server"> 7986.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Offline"> 13078.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Server"> 35365.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Offline"> 45409.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Server"> 32007.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Offline"> 38464.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Server"> 7.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Offline"> 9.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99/Server"> 170023.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99/Offline"> 368654.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99.9/Server"> 170021.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99.9/Offline"> 211128.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Server"> 8801.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Offline"> 9421.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/resnet50/Server"> 410103.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/resnet50/Offline"> 450364.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/3d-unet-99/Offline"> 37.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/3d-unet-99.9/Offline"> 37.1 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0005 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8592+
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json"> ESC-N8-E11 (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> ASUSTeK </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Server"> 20605.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Offline"> 24323.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Server"> 20605.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Offline"> 24323.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Server"> 19226.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Offline"> 19877.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Server"> 19226.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Offline"> 19877.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Server"> 57005.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Offline"> 70661.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Server"> 51213.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Offline"> 62371.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Server"> 15.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Offline"> 16.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99/Server"> 516159.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99/Offline"> 591476.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99.9/Server"> 330066.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99.9/Offline"> 363048.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Server"> 13763.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Offline"> 14432.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/resnet50/Server"> 630229.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/resnet50/Offline"> 709920.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/3d-unet-99/Offline"> 51.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/3d-unet-99.9/Offline"> 51.7 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0006 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8592+
Software: PyTorch
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: Cisco UCS C240 M7. N/A
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json"> C240M7-1-node-2S-EMR-PyTorch </a> </td>
        <td class="col-submitter headcol"> Cisco </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Server"> 113.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Offline"> 252.6 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Server"> 1321.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Offline"> 1678.5 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/dlrm-v2-99/Server"> 9102.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/dlrm-v2-99/Offline"> 10404.5 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Server"> 285.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Offline"> 388.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/resnet50/Server"> 22501.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/resnet50/Offline"> 25643.7 </a> </td>

                <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline"> 1.9 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0007 </td>
        <td class="col-system headcol" title="
Processor: Intel Xeon Gold 6448H
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json"> Cisco UCS C240 M7 (2x L40S, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Cisco </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 2 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Server"> 1734.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Offline"> 1747.7 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Server"> 6761.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Offline"> 6684.8 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Server"> 1.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Offline"> 1.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Server"> 1580.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Offline"> 1642.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/resnet50/Server"> 91209.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C240M7_L40Sx2_TRT/resnet50/Offline"> 87978.3 </a> </td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0008 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9684X 96-Core Processor
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 96.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json"> Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Cisco </td>
        <td class="col-accelerator headcol"> NVIDIA H100-PCIe-80GB x 2 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Server"> 3258.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Offline"> 3268.9 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Server"> 9060.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Offline"> 11576.0 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Server"> 2.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Offline"> 2.5 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Server"> 2101.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Offline"> 2349.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/resnet50/Server"> 102012.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/resnet50/Offline"> 113422.0 </a> </td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0009 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9684X 96-Core Processor
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 96.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json"> Cisco UCS C245 M8 (2x L40S, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Cisco </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 2 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Server"> 1725.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Offline"> 1729.6 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Server"> 6741.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Offline"> 6844.6 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Server"> 1.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Offline"> 1.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Server"> 1600.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Offline"> 1655.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/resnet50/Server"> 90612.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/C245M8_L40Sx2_TRT/resnet50/Offline"> 86700.2 </a> </td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0010 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8592+
Software: PyTorch
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: Cisco UCS X210 M7. N/A
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Cisco/systems/X210M7-1-node-2S-EMR-PyTorch.json"> X210M7-1-node-2S-EMR-PyTorch </a> </td>
        <td class="col-submitter headcol"> Cisco </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Server"> 113.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Offline"> 206.1 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/resnet50/Server"> 22501.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/resnet50/Offline"> 25482.9 </a> </td>

                <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline"> 1.9 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0011 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8562Y+
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json"> Cisco UCS X210c M7 (2x L40S, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Cisco </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 2 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Server"> 1726.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Offline"> 1746.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Server"> 1726.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Offline"> 1746.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Server"> 6781.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Offline"> 6590.3 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Server"> 1.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Offline"> 1.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Server"> 1600.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Offline"> 1648.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0013 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8592+
Software: PyTorch
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: INT4 for GPT-J, and INT8 for all other models
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json"> Dell PowerEdge R760 </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Server"> 113.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Offline"> 248.6 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Server"> 1321.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Offline"> 1685.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server"> 9101.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline"> 9830.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Server"> 285.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Offline"> 373.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/resnet50/Server"> 22501.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/resnet50/Offline"> 25105.8 </a> </td>

                <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline"> 1.9 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0014 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8580
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 120.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json"> Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA H100-PCIe-80GB x 2 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Server"> 2759.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Offline"> 3317.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Server"> 2759.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Offline"> 3317.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Server"> 9145.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Offline"> 11758.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Server"> 8252.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Offline"> 10138.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Server"> 2201.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Offline"> 2314.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/resnet50/Server"> 103012.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/resnet50/Offline"> 112968.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/3d-unet-99/Offline"> 9.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/3d-unet-99.9/Offline"> 9.3 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0015 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8580
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 120.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json"> Dell PowerEdge R760xa (4xH100 NVL, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA H100-NVL-94GB x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Server"> 6337.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Offline"> 7191.4 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Server"> 20104.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Offline"> 24851.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Server"> 17600.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Offline"> 20729.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Server"> 4.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Offline"> 6.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99/Server"> 155014.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99/Offline"> 208212.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99.9/Server"> 118009.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99.9/Offline"> 123033.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Server"> 4802.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Offline"> 5438.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/resnet50/Server"> 220027.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/resnet50/Offline"> 250296.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/3d-unet-99/Offline"> 22.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/3d-unet-99.9/Offline"> 22.3 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0016 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480+
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json"> Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA H100-PCIe-80GB x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Server"> 17880.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Offline"> 23238.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server"> 4502.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Offline"> 4690.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/resnet50/Server"> 206529.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/resnet50/Offline"> 196365.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/3d-unet-99/Offline"> 18.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/3d-unet-99.9/Offline"> 18.6 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0017 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/R760xa_L40Sx4_TRT.json"> Dell PowerEdge R760xa (4x L40S, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Server"> 13853.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Offline"> 13903.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Server"> 3152.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Offline"> 3345.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_L40Sx4_TRT/resnet50/Server"> 181231.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/R760xa_L40Sx4_TRT/resnet50/Offline"> 180613.0 </a> </td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0018 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8468
Software: TensorRT 9.3.0, CUDA 12.2
Cores per processor: 96.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json"> Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 4 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Server"> 9522.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline"> 10699.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server"> 9522.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline"> 10699.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Server"> 9990.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline"> 9966.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Server"> 9990.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline"> 9966.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Server"> 28667.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline"> 35524.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Server"> 25392.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline"> 31392.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server"> 7.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline"> 8.2 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server"> 6791.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Offline"> 7195.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/resnet50/Server"> 310333.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/resnet50/Offline"> 356320.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/3d-unet-99/Offline"> 25.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/3d-unet-99.9/Offline"> 25.7 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0019 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8468
Software: TensorRT 9.3.0, CUDA 12.2
Cores per processor: 96.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json"> Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 4 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Server"> 8937.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline"> 10594.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server"> 8937.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline"> 10594.1 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Server"> 28348.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Offline"> 36051.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Server"> 24854.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Offline"> 31412.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server"> 6.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline"> 8.3 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server"> 6738.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Offline"> 7149.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0020 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8468
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 48.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json"> Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Server"> 21589.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline"> 24086.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server"> 21589.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline"> 24086.7 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Server"> 56011.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline"> 70594.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Server"> 49611.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline"> 61736.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/resnet50/Server"> 584207.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/resnet50/Offline"> 709849.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/3d-unet-99/Offline"> 51.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline"> 51.8 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0021 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8470
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 52.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json"> Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Server"> 29739.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline"> 32124.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server"> 29739.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline"> 32124.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Server"> 20139.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Offline"> 20238.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Server"> 20139.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Offline"> 20238.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Server"> 58091.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Offline"> 73791.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Server"> 51213.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Offline"> 65322.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server"> 16.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline"> 17.7 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Server"> 13603.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Offline"> 14760.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/resnet50/Server"> 630226.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/resnet50/Offline"> 768235.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/3d-unet-99/Offline"> 54.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline"> 54.6 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0022 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8460Y+
Software: vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0
Cores per processor: 40.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Dell/systems/XE9680_MI300X_192GBx8.json"> Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM) </a> </td>
        <td class="col-submitter headcol"> Dell </td>
        <td class="col-accelerator headcol"> AMD MI300X-NPS1-SPX-192GB-750W x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Server"> 19886.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Offline"> 22677.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Server"> 19886.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Offline"> 22677.6 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0024 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Gold 6454S
Software: TensorRT 10.2, CUDA 12.4
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx16_TRT.json"> PRIMERGY CDI (16x L40S, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Fujitsu </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 16 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Server"> 11948.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Offline"> 12048.3 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx16_TRT/3d-unet-99/Offline"> 61.1 </a> </td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0025 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Gold 6454S
Software: TensorRT 10.2, CUDA 12.4
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json"> PRIMERGY CDI (8x L40S, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Fujitsu </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Server"> 3218.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Offline"> 3717.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Server"> 3218.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Offline"> 3717.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Server"> 6903.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Offline"> 6911.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Server"> 6903.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Offline"> 6911.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0026 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8468
Software: TensorRT 10.2, CUDA 12.4
Cores per processor: 48.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json"> GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Fujitsu </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 4 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Server"> 9494.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline"> 10133.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server"> 9494.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline"> 10133.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Server"> 9602.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline"> 9960.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Server"> 9602.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline"> 9960.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Server"> 28605.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Offline"> 36110.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Server"> 25504.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Offline"> 31575.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server"> 7.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline"> 8.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99/Server"> 293303.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99/Offline"> 303974.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Server"> 179024.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Offline"> 190162.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Server"> 6801.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Offline"> 7041.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Server"> 301304.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Offline"> 351603.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/3d-unet-99/Offline"> 25.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/3d-unet-99.9/Offline"> 25.7 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0027 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480+
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json"> GIGABYTE G593-SD1 </a> </td>
        <td class="col-submitter headcol"> GigaComputing </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Server"> 29715.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline"> 31263.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server"> 29715.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline"> 31263.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Server"> 19250.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Offline"> 20041.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Server"> 19250.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Offline"> 20041.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Server"> 58090.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Offline"> 73765.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Server"> 51213.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Offline"> 64368.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server"> 16.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline"> 17.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99/Server"> 585209.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99/Offline"> 639512.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99.9/Server"> 370085.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99.9/Offline"> 394489.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Server"> 14012.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Offline"> 14988.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/resnet50/Server"> 681328.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/resnet50/Offline"> 757446.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/3d-unet-99/Offline"> 54.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline"> 54.4 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0028 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8481C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json"> NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Google </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Server"> 21588.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline"> 24133.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Server"> 21588.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline"> 24133.7 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server"> 15.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline"> 16.3 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Server"> 340068.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline"> 375565.0 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/3d-unet-99/Offline"> 51.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/3d-unet-99.9/Offline"> 51.4 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0029 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 7B13
Software: flax
Cores per processor: 112.0
Processors per node: 1
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Google/systems/tpu_v5e_x4_flax.json"> tpu-v5e-4 </a> </td>
        <td class="col-submitter headcol"> Google </td>
        <td class="col-accelerator headcol"> TPU v5e x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: bf16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/server"> 1.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: bf16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/offline"> 1.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0030 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8592+
Software: PyTorch
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json"> HPE ProLiant DL380 Gen11 </a> </td>
        <td class="col-submitter headcol"> HPE </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Server"> 113.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Offline"> 251.3 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Server"> 1301.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Offline"> 1608.9 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Server"> 275.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Offline"> 370.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/resnet50/Server"> 22501.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/resnet50/Offline"> 25356.7 </a> </td>

                <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline"> 1.9 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0031 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8468
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 48.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json"> HPE Cray XD670 (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> HPE </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Server"> 23132.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline"> 24528.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server"> 23144.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline"> 24424.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Server"> 19502.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Offline"> 19751.9 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Server"> 56729.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Offline"> 71560.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Server"> 51210.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Offline"> 62207.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server"> 15.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline"> 16.2 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Server"> 13763.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Offline"> 14410.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Server"> 620228.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Offline"> 707695.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/3d-unet-99/Offline"> 52.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline"> 52.0 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0032 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) GOLD 6530
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json"> HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> HPE </td>
        <td class="col-accelerator headcol"> NVIDIA H100-NVL-94GB x 4 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Server"> 6927.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Offline"> 8858.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Server"> 6927.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Offline"> 8858.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Server"> 19202.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Offline"> 23937.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Server"> 15003.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Offline"> 20087.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Server"> 3.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Offline"> 5.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Server"> 5003.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Offline"> 5285.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/resnet50/Server"> 240031.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/resnet50/Offline"> 242572.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/3d-unet-99/Offline"> 21.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/3d-unet-99.9/Offline"> 21.5 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0033 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8580
Software: TensorRT 9.0.0, CUDA 12.4
Cores per processor: 60.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json"> HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> HPE </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Server"> 12904.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Offline"> 12981.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Server"> 3102.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Offline"> 3273.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/resnet50/Server"> 176025.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/resnet50/Offline"> 172857.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/3d-unet-99/Offline"> 15.4 </a> </td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0034 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8592+
Software: PyTorch
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: QuantaGrid D54Q-2U. N/A
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json"> 1-node-2S-EMR-PyTorch </a> </td>
        <td class="col-submitter headcol"> Intel </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Server"> 113.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Offline"> 254.7 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Server"> 1281.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Offline"> 1666.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99/Server"> 9731.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99/Offline"> 9949.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server"> 9731.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline"> 9949.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Server"> 285.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Offline"> 377.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/resnet50/Server"> 22501.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/resnet50/Offline"> 25204.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/3d-unet-99/Offline"> 1.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline"> 1.9 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0035 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 7763 64-Core Processor
Software: TensorRT 9.3.0, CUDA 12.2
Cores per processor: 112.0
Processors per node: 2
Nodes: 2
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx16_TRT.json"> 2x8xH100-SXM-80GB </a> </td>
        <td class="col-submitter headcol"> JuniperNetworks </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Server"> 41091.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Offline"> 41672.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Server"> 41091.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Offline"> 41672.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0036 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 7763 64-Core Processor
Software: TensorRT 9.3.0, CUDA 12.2
Cores per processor: 112.0
Processors per node: 2
Nodes: 4
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx32_TRT.json"> 4x8xH100-SXM-80GB </a> </td>
        <td class="col-submitter headcol"> JuniperNetworks </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Server"> 82273.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Offline"> 82749.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Server"> 82273.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Offline"> 82749.6 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0037 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9454
Software: TensorRT 10.2.0, CUDA 12.5
Cores per processor: 48.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json"> ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Lenovo </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Server"> 30068.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Offline"> 31917.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server"> 30068.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline"> 31917.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Server"> 19716.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Offline"> 19859.2 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Server"> 56811.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Offline"> 70319.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Server"> 51211.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Offline"> 62102.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server"> 16.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline"> 17.2 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Server"> 13164.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Offline"> 15015.4 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/3d-unet-99/Offline"> 54.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline"> 54.4 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0038 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8568Y+
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 48.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json"> ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Lenovo </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Server"> 30438.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Offline"> 31973.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Server"> 30438.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Offline"> 31973.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Server"> 19785.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Offline"> 20552.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Server"> 19785.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Offline"> 20552.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Server"> 56012.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Offline"> 70369.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Server"> 52814.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Offline"> 64983.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Server"> 17.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Offline"> 17.6 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/3d-unet-99/Offline"> 54.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/Lenovo_8xH200_TRT/3d-unet-99.9/Offline"> 54.6 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0039 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Gold 6438N
Software: TensorRT 10.2.0, CUDA 12.5
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json"> ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Lenovo </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 3 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Server"> 2475.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Offline"> 2593.7 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Server"> 9302.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Offline"> 9480.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Server"> 2201.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Offline"> 2290.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/resnet50/Server"> 132008.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/resnet50/Offline"> 132436.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR650_V3_3xL40S_TRT/3d-unet-99/Offline"> 11.6 </a> </td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0040 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9634 84-Core Processor
Software: TensorRT 10.2.0, CUDA 12.5
Cores per processor: 84.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json"> ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Lenovo </td>
        <td class="col-accelerator headcol"> NVIDIA H100-NVL-94GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Server"> 13074.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Offline"> 15875.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Server"> 13074.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Offline"> 15875.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Server"> 13083.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Offline"> 14073.6 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Server"> 35006.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Offline"> 47655.3 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Server"> 11.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Offline"> 11.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Server"> 9001.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Offline"> 10867.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/resnet50/Server"> 500148.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/resnet50/Offline"> 541887.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/3d-unet-99/Offline"> 43.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/3d-unet-99.9/Offline"> 43.7 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0043 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json"> NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Server"> 21605.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline"> 24524.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Server"> 21605.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline"> 24524.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Server"> 19233.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline"> 19739.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Server"> 19233.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline"> 19739.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server"> 15.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline"> 16.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Server"> 510155.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline"> 595658.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Server"> 340067.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline"> 361613.0 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0044 </td>
        <td class="col-system headcol" title="
Processor: NVIDIA Grace CPU
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 72.0
Processors per node: 1
Nodes: 1
Notes: NVIDIA GH200 144GB HBM3e
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json"> NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA GH200 Grace Hopper Superchip 144GB x 1 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Server"> 3883.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline"> 4067.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Server"> 3883.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline"> 4067.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Server"> 2513.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline"> 2627.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Server"> 2513.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline"> 2627.7 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server"> 2.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline"> 2.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Server"> 81009.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Offline"> 86731.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Server"> 51014.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Offline"> 53420.6 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0045 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 1000W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx1_TRT.json"> NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB-CTS x 1 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Server"> 4202.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Offline"> 4487.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Server"> 4202.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Offline"> 4487.9 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0046 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 1000W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx8_TRT.json"> NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB-CTS x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Server"> 32789.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Offline"> 34864.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Server"> 32789.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Offline"> 34864.2 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0047 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx1_TRT.json"> NVIDIA H200 (1x H200-SXM-141GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 1 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Server"> 2405.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Offline"> 2579.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Server"> 2405.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Offline"> 2579.5 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0048 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json"> NVIDIA H200 (8x H200-SXM-141GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Server"> 29228.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Offline"> 31302.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Server"> 29228.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Offline"> 31302.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Server"> 19243.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Offline"> 20086.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Server"> 19243.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Offline"> 20086.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Server"> 57609.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Offline"> 73309.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Server"> 51212.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Offline"> 63950.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server"> 16.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline"> 17.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Server"> 585208.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Offline"> 637342.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Server"> 370083.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Offline"> 390953.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Server"> 13604.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Offline"> 14439.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Server"> 632229.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Offline"> 756960.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/3d-unet-99/Offline"> 54.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/3d-unet-99.9/Offline"> 54.7 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0049 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json"> NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Server"> 23113.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Offline"> 25262.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Server"> 23113.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Offline"> 25262.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Server"> 11700.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Offline"> 13096.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Server"> 11700.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Offline"> 13096.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Server"> 41599.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Offline"> 54063.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Server"> 39804.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Offline"> 46534.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Server"> 12.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Offline"> 13.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Server"> 420107.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Offline"> 503719.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Server"> 280045.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline"> 305223.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Server"> 9603.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Offline"> 10802.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Server"> 480131.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Offline"> 556234.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99/Offline"> 41.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99.9/Offline"> 41.7 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0050 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480C
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: H200 TGP 700W
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_Triton.json"> NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA H200-SXM-141GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Server"> 30128.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Offline"> 31059.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Server"> 30128.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Offline"> 31059.3 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0052 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9254 24-Core Processor
Software: vLLM 0.5.2
Cores per processor: 4.0
Processors per node: 2
Nodes: 1
Notes: Automated by MLCommons CM v2.3.3. 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NeuralMagic/systems/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json"> Crusoe Cloud L40S (8x L40S PCIe, vLLM, FP8) </a> </td>
        <td class="col-submitter headcol"> NeuralMagic </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/server"> 592.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline"> 948.2 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0053 </td>
        <td class="col-system headcol" title="
Processor: NVIDIA Grace CPU
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 72.0
Processors per node: 1
Nodes: 1
Notes: NVIDIA MGX Reference Platform;
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json"> NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Oracle </td>
        <td class="col-accelerator headcol"> NVIDIA GH200 Grace Hopper Superchip 96GB x 1 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server"> 2159.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline"> 2695.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server"> 2159.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline"> 2695.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Server"> 6501.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline"> 9864.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Server"> 4502.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline"> 8779.3 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server"> 1731.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Offline"> 1923.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Server"> 77012.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Offline"> 95104.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99/Offline"> 6.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99.9/Offline"> 6.7 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0054 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8592+
Software: PyTorch
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: QuantaGrid D54X-1U
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json"> 1-node-2S-EMR-PyTorch </a> </td>
        <td class="col-submitter headcol"> Quanta_Cloud_Technology </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Server"> 113.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Offline"> 239.0 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Server"> 1241.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Offline"> 1612.0 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server"> 9102.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline"> 9962.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Server"> 280.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Offline"> 372.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/resnet50/Server"> 22501.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/resnet50/Offline"> 24491.1 </a> </td>

                <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline"> 1.9 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0055 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8470
Software: TensorRT 10.2.0.19, CUDA 12.4
Cores per processor: 52.0
Processors per node: 2
Nodes: 1
Notes: QuantaGrid D54U-3U
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json"> D54U_3U_H100_PCIe_80GBx4_TRT </a> </td>
        <td class="col-submitter headcol"> Quanta_Cloud_Technology </td>
        <td class="col-accelerator headcol"> NVIDIA H100-PCIe-80GB x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Server"> 17759.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline"> 23131.4 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Server"> 4.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline"> 4.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Server"> 175023.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Offline"> 184239.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Server"> 100010.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline"> 106363.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server"> 4003.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Offline"> 4633.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Server"> 188028.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Offline"> 224868.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/3d-unet-99/Offline"> 18.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/3d-unet-99.9/Offline"> 18.4 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0056 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8458P
Software: TensorRT 10.2.0.19, CUDA 12.4
Cores per processor: 44.0
Processors per node: 2
Nodes: 1
Notes: QuantaGrid D54U-3U
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json"> D54U_3U_L40S_PCIe_48GBx4_TRT </a> </td>
        <td class="col-submitter headcol"> Quanta_Cloud_Technology </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Server"> 3096.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Offline"> 3463.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Server"> 3096.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline"> 3463.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Server"> 12002.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Offline"> 13248.3 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Server"> 84409.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Offline"> 115424.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Server"> 51015.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Offline"> 51911.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Server"> 3001.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Offline"> 3191.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/resnet50/Server"> 150015.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/resnet50/Offline"> 174603.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/3d-unet-99/Offline"> 15.6 </a> </td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0057 </td>
        <td class="col-system headcol" title="
Processor: NVIDIA Grace CPU
Software: TensorRT 10.2.0.19, CUDA 12.4
Cores per processor: 72.0
Processors per node: 1
Nodes: 1
Notes: QuantaGrid S74G-2U
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json"> GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT </a> </td>
        <td class="col-submitter headcol"> Quanta_Cloud_Technology </td>
        <td class="col-accelerator headcol"> NVIDIA GH200 Grace Hopper Superchip 96GB x 1 </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Server"> 2619.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Offline"> 3114.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server"> 2160.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline"> 2803.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server"> 2160.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline"> 2803.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Server"> 7103.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline"> 9196.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Server"> 6601.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline"> 8092.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Server"> 1.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline"> 2.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Server"> 77511.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline"> 80878.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Server"> 46207.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline"> 48197.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server"> 1731.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Offline"> 1923.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Server"> 73014.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Offline"> 94990.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99/Offline"> 6.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99.9/Offline"> 6.8 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0058 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8480CL
Software: CUDA 12.2
Cores per processor: 112.0
Processors per node: 2
Nodes: 1
Notes: NVIDIA L40S-48GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/RedHat/systems/L40S-RedHat-OpenShift.json"> L40S-RedHat-OpenShift </a> </td>
        <td class="col-submitter headcol"> RedHat </td>
        <td class="col-accelerator headcol"> NVIDIA L40S x 4 </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Server"> 1469.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Offline"> 1717.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0059 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) PLATINUM 8592+
Software: PyTorch
Cores per processor: 64.0
Processors per node: 2
Nodes: 1
Notes: QuantaGrid D54Q-2U. N/A
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Supermicro/systems/1-node-2S-EMR-PyTorch.json"> 1-node-2S-EMR-PyTorch </a> </td>
        <td class="col-submitter headcol"> Supermicro </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Server"> 1256.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Offline"> 1595.1 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/1-node-2S-EMR-PyTorch/resnet50/Server"> 21001.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/1-node-2S-EMR-PyTorch/resnet50/Offline"> 23674.2 </a> </td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0060 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9654
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 96.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json"> AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Supermicro </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Server"> 23699.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline"> 24216.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server"> 23699.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline"> 24216.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Server"> 19810.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline"> 19539.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Server"> 19810.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline"> 19539.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Server"> 57846.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline"> 72222.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Server"> 51049.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline"> 61490.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server"> 15.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline"> 16.1 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server"> 354036.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline"> 370389.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server"> 13803.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Offline"> 14460.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Server"> 632629.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Offline"> 708730.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99/Offline"> 52.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline"> 52.3 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0061 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9474F
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 48.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json"> AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Supermicro </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Server"> 21775.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline"> 24011.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server"> 21775.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline"> 24011.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Server"> 19304.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline"> 19418.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Server"> 19304.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline"> 19418.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Server"> 57488.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline"> 71861.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Server"> 50729.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline"> 61128.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server"> 15.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline"> 16.0 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server"> 354035.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline"> 359682.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server"> 13731.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Offline"> 14244.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/resnet50/Server"> 633551.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/resnet50/Offline"> 703377.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99/Offline"> 52.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline"> 52.1 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0062 </td>
        <td class="col-system headcol" title="
Processor: NVIDIA Grace CPU
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 72.0
Processors per node: 1
Nodes: 1
Notes: NVIDIA MGX Reference Platform;
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Supermicro/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json"> NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Supermicro </td>
        <td class="col-accelerator headcol"> NVIDIA GH200 Grace Hopper Superchip 96GB x 1 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server"> 2159.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline"> 2659.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server"> 2159.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline"> 2659.5 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0063 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8570
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 56.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json"> SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Supermicro </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Server"> 21888.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline"> 24180.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server"> 21888.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline"> 24180.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Server"> 19725.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline"> 19808.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Server"> 19725.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline"> 19808.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Server"> 58928.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline"> 72876.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Server"> 52049.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline"> 62036.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server"> 16.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline"> 16.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99/Server"> 556101.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline"> 602108.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server"> 358000.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline"> 372277.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server"> 13979.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Offline"> 14538.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Server"> 633672.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Offline"> 710521.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99/Offline"> 52.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline"> 52.2 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0064 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8468
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 48.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json"> SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Supermicro </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Server"> 21986.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline"> 24140.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server"> 21986.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline"> 24140.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Server"> 19635.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline"> 19803.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Server"> 19635.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline"> 19803.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Server"> 57928.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline"> 71806.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Server"> 51570.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline"> 62153.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server"> 16.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline"> 16.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Server"> 548900.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline"> 592829.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server"> 356561.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline"> 363656.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server"> 13803.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Offline"> 14405.1 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/resnet50/Server"> 634193.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/resnet50/Offline"> 707052.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99/Offline"> 52.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline"> 52.2 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0065 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Platinum 8462Y+
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json"> SMC H100 (8x H100-SXM-80GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> Sustainable_Metal_Cloud </td>
        <td class="col-accelerator headcol"> NVIDIA H100-SXM-80GB x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Server"> 21327.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Offline"> 24459.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Server"> 21327.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Offline"> 24459.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Server"> 19233.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Offline"> 19711.1 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Server"> 56008.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Offline"> 69043.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Server"> 49613.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Offline"> 61778.8 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99/Server"> 510155.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99/Offline"> 597885.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99.9/Server"> 340067.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99.9/Offline"> 369334.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Server"> 12884.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Offline"> 14405.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/resnet50/Server"> 584207.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/resnet50/Offline"> 706789.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/3d-unet-99/Offline"> 51.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/3d-unet-99.9/Offline"> 51.8 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0066 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Gold 6448Y
Software: UntetherAI imAIgine SDK v24.07.19
Cores per processor: 32.0
Processors per node: 2
Nodes: 1
Notes: Powered by the KRAI X and KILT technologies
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/UntetherAI/systems/r760_u6_slim.json"> Dell PowerEdge R760xa (6x speedAI240 Slim) </a> </td>
        <td class="col-submitter headcol"> UntetherAI </td>
        <td class="col-accelerator headcol"> UntetherAI speedAI240 Slim x 6 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: float8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/UntetherAI/results/r760_u6_slim/resnet50/server"> 309752.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: float8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/UntetherAI/results/r760_u6_slim/resnet50/offline"> 334462.0 </a> </td>

                <td></td>

                <td></td>

        </tr>
        </table></div>

<!-- pager -->
<div class="pager1 PAGER_CLASS">
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/first.png" class="first"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/prev.png" class="prev"/>
            <span class="pagedisplay"></span> <!-- this can be any element, including an input -->
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/next.png" class="next"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/last.png" class="last"/>
            <select class="pagesize" title="Select page size">
            <option selected="selected" value="10">10</option>
            <option value="20">20</option>
            <option value="30">30</option>
            <option value="all">All</option>
            </select>
            <select class="gotoPage" title="Select page number"></select>
</div>

<hr>

        <h2 id="results_heading_preview" class="results_table_heading">Datacenter Category: Preview submissions in Closed division</h2>

<!-- pager -->
<div class="pager1 PAGER_CLASS">
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/first.png" class="first"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/prev.png" class="prev"/>
            <span class="pagedisplay"></span> <!-- this can be any element, including an input -->
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/next.png" class="next"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/last.png" class="last"/>
            <select class="pagesize" title="Select page size">
            <option selected="selected" value="10">10</option>
            <option value="20">20</option>
            <option value="30">30</option>
            <option value="all">All</option>
            </select>
            <select class="gotoPage" title="Select page number"></select>
</div>

<div id="results_table_preview" class="resultstable_wrapper"> <table class="resultstable tablesorter tableclosed tabledatacenter" id="results_preview"><thead> <tr>
            <th id="col-id" class="headcol col-id">ID</th>
            <th id="col-system" class="headcol col-system">System</th>
            <th id="col-submitter" class="headcol col-submitter">Submitter</th>
            <th id="col-accelerator" class="headcol col-accelerator">Accelerator</th>
            <th id="col-llama2-99" colspan="2">LLAMA2-70B-99</th>
            <th id="col-llama2-99.9" colspan="2">LLAMA2-70B-99.9</th>
            <th id="col-gptj-99" colspan="2">GPTJ-99</th>
            <th id="col-gptj-99.9" colspan="2">GPTJ-99.9</th>
            <th id="col-bert-99" colspan="2">Bert-99</th>
            <th id="col-bert-99.9" colspan="2">Bert-99.9</th>
            <th id="col-sdxl" colspan="2">Stable Diffusion</th>
            <th id="col-dlrm-v2-99" colspan="2">DLRM-v2-99</th>
            <th id="col-dlrm-v2-99.9" colspan="2">DLRM-v2-99.9</th>
            <th id="col-retinanet" colspan="2">Retinanet</th>
            <th id="col-resnet50" colspan="2">ResNet50</th>
            <th id="col-3d-unet-99" colspan="1">3d-unet-99</th>
            <th id="col-3d-unet-99.9" colspan="1">3d-unet-99.9</th>
            </tr>
        <tr>
        <th class="headcol col-id"></th>
        <th class="headcol col-system"></th>
        <th class="headcol col-submitter"></th>
        <th class="headcol col-accelerator"></th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>
                </tr></thead><tfoot> <tr>
            <th id="col-id" class="headcol col-id">ID</th>
            <th id="col-system" class="headcol col-system">System</th>
            <th id="col-submitter" class="headcol col-submitter">Submitter</th>
            <th id="col-accelerator" class="headcol col-accelerator">Accelerator</th>
            <th id="col-llama2-99" colspan="2">LLAMA2-70B-99</th>
            <th id="col-llama2-99.9" colspan="2">LLAMA2-70B-99.9</th>
            <th id="col-gptj-99" colspan="2">GPTJ-99</th>
            <th id="col-gptj-99.9" colspan="2">GPTJ-99.9</th>
            <th id="col-bert-99" colspan="2">Bert-99</th>
            <th id="col-bert-99.9" colspan="2">Bert-99.9</th>
            <th id="col-sdxl" colspan="2">Stable Diffusion</th>
            <th id="col-dlrm-v2-99" colspan="2">DLRM-v2-99</th>
            <th id="col-dlrm-v2-99.9" colspan="2">DLRM-v2-99.9</th>
            <th id="col-retinanet" colspan="2">Retinanet</th>
            <th id="col-resnet50" colspan="2">ResNet50</th>
            <th id="col-3d-unet-99" colspan="1">3d-unet-99</th>
            <th id="col-3d-unet-99.9" colspan="1">3d-unet-99.9</th>
            </tr>
        <tr>
        <th class="headcol col-id"></th>
        <th class="headcol col-system"></th>
        <th class="headcol col-submitter"></th>
        <th class="headcol col-accelerator"></th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Server</th>
                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>

                <th class="col-scenario">Offline</th>
                </tr></tfoot>
        <tr>
        <td class="col-id headcol"> v4.1-0070 </td>
        <td class="col-system headcol" title="
Processor: 2xAMD EPYC TURIN
Software: vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2
Cores per processor: 
Processors per node: 2
Nodes: 1
Notes: Preview due to using AMD next-generation EPYC CPU
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-TURIN.json"> Supermicro AS-8125GS-TNMR2 </a> </td>
        <td class="col-submitter headcol"> AMD </td>
        <td class="col-accelerator headcol"> AMD Instinct MI300X-NPS1-SPX-192GB-750W x 8 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Server"> 22020.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Offline"> 24109.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Server"> 22020.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Offline"> 24109.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0071 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9B14
Software: flax
Cores per processor: 180.0
Processors per node: 1
Nodes: 1
Notes: 
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Google/systems/tpu_v6_x4_flax.json"> tpu-v6-4 </a> </td>
        <td class="col-submitter headcol"> Google </td>
        <td class="col-accelerator headcol"> TPU v6 x 4 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: bf16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/server"> 4.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: bf16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/offline"> 5.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0072 </td>
        <td class="col-system headcol" title="
Processor: NVIDIA Grace CPU
Software: TensorRT 10.2.0, CUDA 12.4
Cores per processor: 72.0
Processors per node: 1
Nodes: 1
Notes: NVIDIA GH200 144GB HBM3e
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json"> HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT) </a> </td>
        <td class="col-submitter headcol"> HPE </td>
        <td class="col-accelerator headcol"> NVIDIA GH200 Grace Hopper Superchip 144GB x 1 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Server"> 3884.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline"> 4084.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Server"> 3884.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline"> 4084.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Server"> 2512.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline"> 2632.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Server"> 2512.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline"> 2632.8 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server"> 2.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline"> 2.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Server"> 81009.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Offline"> 87052.7 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Server"> 51014.2 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Offline"> 53611.9 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0073 </td>
        <td class="col-system headcol" title="
Processor: INTEL(R) XEON(R) 6980P
Software: PyTorch
Cores per processor: 128.0
Processors per node: 2
Nodes: 1
Notes: Intel AvenueCity. N/A
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json"> 1-node-2S-GNR-PyTorch </a> </td>
        <td class="col-submitter headcol"> Intel </td>
        <td class="col-accelerator headcol">  </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Server"> 217.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int4" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Offline"> 498.3 </a> </td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Server"> 2437.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Offline"> 3024.0 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99/Server"> 17749.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99/Offline"> 18326.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99.9/Server"> 17749.5 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99.9/Offline"> 18326.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Server"> 595.8 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Offline"> 746.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/resnet50/Server"> 39798.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: INT8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/resnet50/Offline"> 45617.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/3d-unet-99/Offline"> 3.3 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: int8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/Intel/results/1-node-2S-GNR-PyTorch/3d-unet-99.9/Offline"> 3.3 </a> </td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0074 </td>
        <td class="col-system headcol" title="
Processor: Intel(R) Xeon(R) Silver 4410Y
Software: TensorRT 10.1.0, CUDA 12.7
Cores per processor: 12.0
Processors per node: 1
Nodes: 1
Notes: B200 TGP 1000W. Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/NVIDIA/systems/B200-SXM-180GBx1_TRT.json"> NVIDIA B200 (1x B200-SXM-180GB, TensorRT) </a> </td>
        <td class="col-submitter headcol"> NVIDIA </td>
        <td class="col-accelerator headcol"> NVIDIA B200-SXM-180GB x 1 </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Server"> 10755.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Offline"> 11264.4 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Server"> 10755.6 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: fp16" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Offline"> 11264.4 </a> </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0075 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9124 16-Core Processor
Software: UntetherAI imAIgine SDK v24.07.19
Cores per processor: 16.0
Processors per node: 1
Nodes: 1
Notes: Powered by the KRAI X and KILT technologies
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_preview_dc.json"> Supermicro SuperServer H13 (1x speedAI240 Preview) </a> </td>
        <td class="col-submitter headcol"> UntetherAI </td>
        <td class="col-accelerator headcol"> UntetherAI speedAI240 Preview x 1 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: float8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/UntetherAI/results/h13_u1_preview_dc/resnet50/server"> 70096.9 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: float8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/UntetherAI/results/h13_u1_preview_dc/resnet50/offline"> 70348.6 </a> </td>

                <td></td>

                <td></td>

        </tr>

        <tr>
        <td class="col-id headcol"> v4.1-0076 </td>
        <td class="col-system headcol" title="
Processor: AMD EPYC 9124 16-Core Processor
Software: UntetherAI imAIgine SDK v24.07.19
Cores per processor: 16.0
Processors per node: 1
Nodes: 1
Notes: Powered by the KRAI X and KILT technologies
        "> <a target="_blank" href="https://github.com/gateoverflow/inference_systems_v4.1/tree/main/closed/UntetherAI/systems/h13_u2_preview_dc.json"> Supermicro SuperServer H13 (2x speedAI240 Preview) </a> </td>
        <td class="col-submitter headcol"> UntetherAI </td>
        <td class="col-accelerator headcol"> UntetherAI speedAI240 Preview x 2 </td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

                <td></td>

                    <td></td>

            <td class="col-result"><a target="_blank" title="Model precision: float8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/UntetherAI/results/h13_u2_preview_dc/resnet50/server"> 140239.0 </a> </td>

            <td class="col-result"><a target="_blank" title="Model precision: float8" href="https://github.com/GATEOverflow/inference_results_v4.1/tree/GATEOverflow/closed/UntetherAI/results/h13_u2_preview_dc/resnet50/offline"> 140631.0 </a> </td>

                <td></td>

                <td></td>

        </tr>
        </table></div>

<!-- pager -->
<div class="pager1 PAGER_CLASS">
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/first.png" class="first"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/prev.png" class="prev"/>
            <span class="pagedisplay"></span> <!-- this can be any element, including an input -->
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/next.png" class="next"/>
            <img src="https://mottie.github.io/tablesorter/addons/pager/icons/last.png" class="last"/>
            <select class="pagesize" title="Select page size">
            <option selected="selected" value="10">10</option>
            <option value="20">20</option>
            <option value="30">30</option>
            <option value="all">All</option>
            </select>
            <select class="gotoPage" title="Select page number"></select>
</div>

<hr>

<h2 id="count_heading">Count of Results </h2>

    <div class="counttable_wrapper">
    <table class="tablesorter counttable" id="results_summary">
    <thead>
    <tr>
    <th class="count-submitter">Submitter</th>

            <th id="col-llama2-99">LLAMA2-70B-99</th>
            <th id="col-llama2-99.9">LLAMA2-70B-99.9</th>
            <th id="col-gptj-99">GPTJ-99</th>
            <th id="col-gptj-99.9">GPTJ-99.9</th>
            <th id="col-bert-99">Bert-99</th>
            <th id="col-bert-99.9">Bert-99.9</th>
            <th id="col-dlrm-v2-99">Stable Diffusion</th>
            <th id="col-dlrm-v2-99">DLRM-v2-99</th>
            <th id="col-dlrm-v2-99.9">DLRM-v2-99.9</th>
            <th id="col-retinanet">Retinanet</th>
            <th id="col-resnet50">ResNet50</th>
            <th id="col-3d-unet-99">3d-unet-99</th>
            <th id="col-3d-unet-99.9">3d-unet-99.9</th>
            <th id="all-models">Total</th>
            </tr>
            </thead>
            <tr><td class="count-submitter"> AMD </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 12 </td></tr><tr><td class="count-submitter"> ASUSTeK </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 3 </td><td class="col-result"> 3 </td><td class="col-result"> 72 </td></tr><tr><td class="count-submitter"> Cisco </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 12 </td><td class="col-result"> 2 </td><td class="col-result"> 10 </td><td class="col-result"> 0 </td><td class="col-result"> 8 </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 10 </td><td class="col-result"> 10 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 56 </td></tr><tr><td class="count-submitter"> Dell </td><td class="col-result"> 10 </td><td class="col-result"> 10 </td><td class="col-result"> 10 </td><td class="col-result"> 6 </td><td class="col-result"> 18 </td><td class="col-result"> 12 </td><td class="col-result"> 8 </td><td class="col-result"> 2 </td><td class="col-result"> 4 </td><td class="col-result"> 16 </td><td class="col-result"> 16 </td><td class="col-result"> 6 </td><td class="col-result"> 7 </td><td class="col-result"> 125 </td></tr><tr><td class="count-submitter"> Fujitsu </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 4 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 1 </td><td class="col-result"> 35 </td></tr><tr><td class="count-submitter"> GigaComputing </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 1 </td><td class="col-result"> 1 </td><td class="col-result"> 24 </td></tr><tr><td class="count-submitter"> Google </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 6 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 1 </td><td class="col-result"> 1 </td><td class="col-result"> 14 </td></tr><tr><td class="count-submitter"> HPE </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 2 </td><td class="col-result"> 8 </td><td class="col-result"> 4 </td><td class="col-result"> 6 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 3 </td><td class="col-result"> 3 </td><td class="col-result"> 64 </td></tr><tr><td class="count-submitter"> Intel </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 4 </td><td class="col-result"> 0 </td><td class="col-result"> 4 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 28 </td></tr><tr><td class="count-submitter"> JuniperNetworks </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 8 </td></tr><tr><td class="count-submitter"> Lenovo </td><td class="col-result"> 6 </td><td class="col-result"> 6 </td><td class="col-result"> 8 </td><td class="col-result"> 2 </td><td class="col-result"> 8 </td><td class="col-result"> 4 </td><td class="col-result"> 6 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 6 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 3 </td><td class="col-result"> 57 </td></tr><tr><td class="count-submitter"> NVIDIA </td><td class="col-result"> 16 </td><td class="col-result"> 16 </td><td class="col-result"> 10 </td><td class="col-result"> 10 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 96 </td></tr><tr><td class="count-submitter"> NeuralMagic </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td></tr><tr><td class="count-submitter"> Oracle </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 1 </td><td class="col-result"> 1 </td><td class="col-result"> 14 </td></tr><tr><td class="count-submitter"> Quanta_Cloud_Technology </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 6 </td><td class="col-result"> 4 </td><td class="col-result"> 8 </td><td class="col-result"> 2 </td><td class="col-result"> 4 </td><td class="col-result"> 6 </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 3 </td><td class="col-result"> 3 </td><td class="col-result"> 62 </td></tr><tr><td class="count-submitter"> RedHat </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td></tr><tr><td class="count-submitter"> Supermicro </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 10 </td><td class="col-result"> 10 </td><td class="col-result"> 10 </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 4 </td><td class="col-result"> 8 </td><td class="col-result"> 8 </td><td class="col-result"> 10 </td><td class="col-result"> 4 </td><td class="col-result"> 4 </td><td class="col-result"> 100 </td></tr><tr><td class="count-submitter"> Sustainable_Metal_Cloud </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 0 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 2 </td><td class="col-result"> 1 </td><td class="col-result"> 1 </td><td class="col-result"> 20 </td></tr><tr><td class="count-submitter"> UntetherAI </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 6 </td><td class="col-result"> 0 </td><td class="col-result"> 0 </td><td class="col-result"> 6 </td></tr>
    <tr>
    <td class="count-submitter">Total</td>
    <td class="col-result"> 74 </td><td class="col-result"> 76 </td><td class="col-result"> 82 </td><td class="col-result"> 50 </td><td class="col-result"> 84 </td><td class="col-result"> 48 </td><td class="col-result"> 64 </td><td class="col-result"> 40 </td><td class="col-result"> 48 </td><td class="col-result"> 80 </td><td class="col-result"> 84 </td><td class="col-result"> 33 </td><td class="col-result"> 34 </td><td class="col-result"> 797 </td></tr></table></div>
<hr>

    <div id="submittervssubmissionchartContainer" class="bgtext" style="height:370px; width:80%; margin:auto;"></div>
    <div id="modelvssubmissionchartContainer" class="bgtext" style="height:370px; width:80%; margin:auto;"></div>

    <form id="resultSelectionForm" method="post" action="">
        <h3>Select Category and Division</h3>

        <div class="form-field">
            <label for="category">Category</label>
            <select id="category" name="category" class="col">
                <option value='datacenter' selected>Datacenter</option>
<option value='edge' >Edge</option>

            </select>
        </div>

        <div class="form-field">
            <label for="division">Division</label>
            <select id="division" name="division" class="col">
                <option value='closed' selected>Closed</option>
<option value='open' >Open</option>

            </select>
        </div>

        <div class="form-field">
            <label for="with_power">Power</label>
            <select id="with_power" name="with_power" class="col">
                <option value="true" >Performance and Power</option>
                <option value="false" selected>Performance</option>
            </select>
        </div>

        <div class="form-field">
            <button type="submit" name="submit" value="1" id="results_tablesorter">Submit</button>
        </div>
    </form>


<script type="text/javascript">
var sortcolumnindex = 6, perfsortorder = 1;
$('#submittervssubmissionchartContainer').hide();
$('#modelvssubmissionchartContainer').hide();
</script>

<script type="text/javascript" src="javascripts/init_tablesorter.js"></script>
<script type="text/javascript" src="javascripts/results_tablesorter.js"></script>
<script type="text/javascript" src="javascripts/chart_results.js"></script>

</html>







  
  




  



                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": ".", "features": ["content.tabs.link", "content.code.copy", "navigation.expand", "navigation.sections", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "toc.follow"], "search": "assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
  
      <script src="assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  <script type"text/javascript">
  var resort = true, // re-apply the current sort
        callback = function() {
          // do something after the updateAll method has completed
        };

      // let the plugin know that we made a update, then the plugin will
      // automatically sort the table based on the header settings
      $("table").trigger("updateAll", [ resort, callback ]);
  </script>


  </body>
</html>